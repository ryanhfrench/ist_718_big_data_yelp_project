{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_logo.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Yelp Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from pyspark import sql\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset available at: https://www.kaggle.com/yelp-dataset/yelp-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685900"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = '/Users/ryanfrench/Dropbox/cloud_documents/college/9_fall_2019/IST_718/yelp_dataset/yelp_academic_dataset_review.json'\n",
    "reviews_df = spark.read.json(path)\n",
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REMEMBER TO REMOVE THIS, THIS SAMPLES ONLY 1/1000 OF THE DATA!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.sample(False, 0.001, seed = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema\n",
    "reviews_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of NULL values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id : 0\n",
      "cool : 0\n",
      "date : 0\n",
      "funny : 0\n",
      "review_id : 0\n",
      "stars : 0\n",
      "text : 0\n",
      "useful : 0\n",
      "user_id : 0\n"
     ]
    }
   ],
   "source": [
    "for col in reviews_df.columns:\n",
    "    print(col, ':', reviews_df.filter(reviews_df[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|hcFSc0OHgZJybnjQB...|   0|2014-02-05 18:10:23|    0|4CMCRoNZgmxwtOBLG...|  5.0|Fresher noodles y...|     0|5BfyObsvVjB6zcj8W...|\n",
      "|HhVmDybpU7L50Kb5A...|   0|2017-06-06 19:51:49|    0|QdXaCGCQtvSiue-0m...|  2.0|I would not be go...|     0|zPByj_3y6TBok5BpC...|\n",
      "|XXCIO_TXCE1uQWPLr...|   1|2015-03-04 19:51:08|    1|uqAUjIy1OKnNl1rzJ...|  1.0|Don't waste your ...|     1|EZxdmp1_mXzPaHreZ...|\n",
      "|Hpi9raHlFm6prTSzF...|   1|2018-07-07 21:56:54|    1|UldTdufMzctB0llHL...|  2.0|On a second visit...|     2|moj7DUHkP4j9yfwFm...|\n",
      "|cisqOxAgQPjVVr9Yz...|   0|2018-07-26 14:25:15|    0|ylZjXOIZZqZPBRztX...|  4.0|I absolutely love...|     0|TX5kwQLpKUDvNf4mf...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6585"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.show(5)\n",
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we predict high star Yelp reviews based off of their text content?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By creating a text transformation and prediction pipeline can we predict which Yelp reviews will have a high number of stars (4/5 or above)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variable for high reviews (defined as a 4/5 or above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By creating a dummy variable we can easily predict the binary outcomes of low vs high reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|d_stars|count|\n",
      "+-------+-----+\n",
      "|      1| 4341|\n",
      "|      0| 2244|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df = reviews_df.withColumn('d_stars',when(col('stars')>=4, 1).otherwise(0))\n",
    "reviews_df = reviews_df.select('d_stars', 'text')\n",
    "reviews_df.groupBy('d_stars').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|d_stars|                text|\n",
      "+-------+--------------------+\n",
      "|      1|Fresher noodles y...|\n",
      "|      0|I would not be go...|\n",
      "|      0|Don't waste your ...|\n",
      "|      0|On a second visit...|\n",
      "|      1|I absolutely love...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reviews_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize 'text' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By tokenizing the 'text' column we can break out the long strings of review text into their individual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCol('text').setOutputCol('tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample output of Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|d_stars|                text|              tokens|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|Fresher noodles y...|[fresher, noodles...|\n",
      "|      0|I would not be go...|[i, would, not, b...|\n",
      "|      0|Don't waste your ...|[don't, waste, yo...|\n",
      "|      0|On a second visit...|[on, a, second, v...|\n",
      "|      1|I absolutely love...|[i, absolutely, l...|\n",
      "|      0|This place USED t...|[this, place, use...|\n",
      "|      0|Beware. My dog wa...|[beware., my, dog...|\n",
      "|      1|First time here w...|[first, time, her...|\n",
      "|      1|Plumbing Update w...|[plumbing, update...|\n",
      "|      1|I frequent this p...|[i, frequent, thi...|\n",
      "|      1|This is my second...|[this, is, my, se...|\n",
      "|      0|The front desk st...|[the, front, desk...|\n",
      "|      1|Great service, sm...|[great, service,,...|\n",
      "|      1|Love this place! ...|[love, this, plac...|\n",
      "|      1|This is so much f...|[this, is, so, mu...|\n",
      "|      1|The pollo mole is...|[the, pollo, mole...|\n",
      "|      1|We recently hit u...|[we, recently, hi...|\n",
      "|      1|I really liked th...|[i, really, liked...|\n",
      "|      0|This just the caf...|[this, just, the,...|\n",
      "|      0|Scrambled eggs ar...|[scrambled, eggs,...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.transform(reviews_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get NTLK stop words from GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop words are words which are generally considered to offer little insight in linguistic processing due to the fact that they are utilized so frequently. We will be utilizing the list contained in the Natural Language Tool Kit (NLTK) to remove these words in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "stop_words = requests.get('https://gist.github.com/sebleier/554280').text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "sw_filter = StopWordsRemover(). \\\n",
    "            setStopWords(stop_words). \\\n",
    "            setCaseSensitive(False). \\\n",
    "            setInputCol(\"tokens\"). \\\n",
    "            setOutputCol(\"filtered_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADJUST THE MINDF PARAM WITH FULL REVIEWS TAKEN INTO ACCOUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CountVectorizer Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The CountVectorizer counts the number of times that a token appears in each review and then saves this list of numbers as a vector for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# we will remove words that appear in 50 docs or less\n",
    "cv = CountVectorizer(minTF=1., minDF=6, vocabSize=2**17). \\\n",
    "     setInputCol(\"filtered_tokens\"). \\\n",
    "     setOutputCol(\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create initial text processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample output of initial text processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|d_stars|                text|              tokens|     filtered_tokens|                  tf|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      1|Fresher noodles y...|[fresher, noodles...|[fresher, noodles...|(6567,[3,8,11,17,...|\n",
      "|      0|I would not be go...|[i, would, not, b...|[back.., personal...|(6567,[0,4,14,18,...|\n",
      "|      0|Don't waste your ...|[don't, waste, yo...|[waste, money., 5...|(6567,[0,8,25,37,...|\n",
      "|      0|On a second visit...|[on, a, second, v...|[visit,, changed....|(6567,[0,6,7,8,54...|\n",
      "|      1|I absolutely love...|[i, absolutely, l...|[absolutely, chat...|(6567,[0,1,3,7,9,...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_pipeline.transform(reviews_df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Inverse Document Frequency (IDF) stage for the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will lower the realtive value of tokens which appear frequently in documents allowing those that are more specialized to stand out more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "\n",
    "idf = IDF(). \\\n",
    "      setInputCol('tf'). \\\n",
    "      setOutputCol('tfidf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IDF text processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(reviews_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample output of IDF text processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|d_stars|                text|              tokens|     filtered_tokens|                  tf|               tfidf|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      1|Fresher noodles y...|[fresher, noodles...|[fresher, noodles...|(6567,[3,8,11,17,...|(6567,[3,8,11,17,...|\n",
      "|      0|I would not be go...|[i, would, not, b...|[back.., personal...|(6567,[0,4,14,18,...|(6567,[0,4,14,18,...|\n",
      "|      0|Don't waste your ...|[don't, waste, yo...|[waste, money., 5...|(6567,[0,8,25,37,...|(6567,[0,8,25,37,...|\n",
      "|      0|On a second visit...|[on, a, second, v...|[visit,, changed....|(6567,[0,6,7,8,54...|(6567,[0,6,7,8,54...|\n",
      "|      1|I absolutely love...|[i, absolutely, l...|[absolutely, chat...|(6567,[0,1,3,7,9,...|(6567,[0,1,3,7,9,...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf_pipeline.transform(reviews_df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Text Frequency Inverse Document Frequency (TFIDF) Reviews Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By passing the reviews data frame to the IDF pipeline we can create a TFIDF dataframe which we will then use to predict the review scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = idf_pipeline.transform(reviews_df)\n",
    "pd_tfidf_df = tfidf_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d_stars', 'text', 'tokens', 'filtered_tokens', 'tf', 'tfidf']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_stars</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.3560841977020832, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(2.9074505057164317, 0.0, 0.0, 0.0, 1.41744568...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>(1.1629802022865727, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>(3.4889406068597184, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(1.1629802022865727, 1.328191628299782, 0.0, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_stars                                              tfidf\n",
       "0        1  (0.0, 0.0, 0.0, 1.3560841977020832, 0.0, 0.0, ...\n",
       "1        0  (2.9074505057164317, 0.0, 0.0, 0.0, 1.41744568...\n",
       "2        0  (1.1629802022865727, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3        0  (3.4889406068597184, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4        1  (1.1629802022865727, 1.328191628299782, 0.0, 1..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_df = pd_tfidf_df[['d_stars', 'tfidf']]\n",
    "lr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prediction pipeline for estimating high star reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training, validation, and testing groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df, test_df = reviews_df.randomSplit([0.6, 0.3, 0.1], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of training records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3942"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of validation records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of testing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "626"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build logistic regression model for later predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lr = LogisticRegression(). \\\n",
    "     setLabelCol('d_stars'). \\\n",
    "     setFeaturesCol('tfidf'). \\\n",
    "     setRegParam(0.0). \\\n",
    "     setMaxIter(100). \\\n",
    "     setElasticNetParam(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new pipeline for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lr_estimator = Pipeline(stages=[tokenizer, \n",
    "                                   sw_filter, \n",
    "                                   cv, \n",
    "                                   idf, \n",
    "                                   en_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build grid search estimator pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This will allow us to iteratively search for the optimal $\\lambda$ and $\\alpha$ parameters to achieve the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tokenizer_44dbea8f2808,\n",
       " StopWordsRemover_b51a0393d1ab,\n",
       " CountVectorizer_758f5f2a3056,\n",
       " IDF_ab3e96ba3323,\n",
       " LogisticRegression_adde6b5d10b3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lr_estimator.getStages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a pipeline transformation by chaining the `idf_pipeline` with the logistic regression step (`lr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder(). \\\n",
    "       addGrid(en_lr.regParam, [0., 0.01, 0.02]). \\\n",
    "       addGrid(en_lr.elasticNetParam, [0., 0.2, 0.4]). \\\n",
    "       build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "\n",
    "for j in range(len(grid)):\n",
    "    print(\"Fitting model {}\".format(j+1))\n",
    "    model = en_lr_estimator.fit(train_df, grid[j])\n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as fn\n",
    "\n",
    "accuracies = [m. \\\n",
    "              transform(validation_df). \\\n",
    "              select(fn.avg(fn.expr('float(d_stars = prediction)')).alias('accuracy')). \\\n",
    "              first(). \\\n",
    "              accuracy for m in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7962320277640059,\n",
       " 0.7962320277640059,\n",
       " 0.7962320277640059,\n",
       " 0.8170550322260783,\n",
       " 0.8230044620723848,\n",
       " 0.819533961328706,\n",
       " 0.8215171046108082,\n",
       " 0.8190381755081805,\n",
       " 0.8081308874566188]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model index = 4\n"
     ]
    }
   ],
   "source": [
    "best_model_idx = np.argmax(accuracies)\n",
    "print(\"best model index =\", best_model_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the grid parameters of the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_adde6b5d10b3', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       " Param(parent='LogisticRegression_adde6b5d10b3', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_models[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8230044620723848"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          accuracy|\n",
      "+------------------+\n",
      "|0.8514376996805112|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimate generalization performance\n",
    "best_model. \\\n",
    "    transform(test_df). \\\n",
    "    select(fn.avg(fn.expr('float(d_stars = prediction)')).alias('accuracy')). \\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a pipeline transformation by chaining the `idf_pipeline` with the logistic regression step (`lr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline(stages=[idf_pipeline, en_lr]).fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets estimate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.7992067426871592|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline.transform(validation_df). \\\n",
    "            select(fn.expr('float(prediction = d_stars)').alias('correct')). \\\n",
    "            select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
