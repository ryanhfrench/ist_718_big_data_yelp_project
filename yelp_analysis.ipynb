{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"yelp_logo.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Yelp Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark\n",
    "from pyspark import sql\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6685900"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = 'yelp-dataset/yelp_academic_dataset_review.json'\n",
    "reviews_df = spark.read.json(path)\n",
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = reviews_df.sample(False, 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- business_id: string (nullable = true)\n",
      " |-- cool: long (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- funny: long (nullable = true)\n",
      " |-- review_id: string (nullable = true)\n",
      " |-- stars: double (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- useful: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check schema\n",
    "reviews_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check number of NULL values per column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business_id : 0\n",
      "cool : 0\n",
      "date : 0\n",
      "funny : 0\n",
      "review_id : 0\n",
      "stars : 0\n",
      "text : 0\n",
      "useful : 0\n",
      "user_id : 0\n"
     ]
    }
   ],
   "source": [
    "for col in reviews_df.columns:\n",
    "    print(col, ':', reviews_df.filter(reviews_df[col].isNull()).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|         business_id|cool|               date|funny|           review_id|stars|                text|useful|             user_id|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "|aRNjAsmXv1pJTUWTt...|   0|2016-07-25 05:34:02|    0|4gsMjBlKGdWsdvytf...|  5.0|I don't usually r...|     1|H74Dv2uhRcfYurTwL...|\n",
      "|r48H_sNUGmcRGX1Ls...|   0|2013-06-24 13:21:01|    0|NNHMeimS_JPdPFkG6...|  3.0|Food was dece. Se...|     0|QrIvOhNFzEBRUU2Rb...|\n",
      "|cbdg2vJ6vM6Vq2EaJ...|   0|2016-10-01 17:19:34|    0|mVN3VPcaYJeGWN7sy...|  5.0|Boca Park Animal ...|     0|VlQMznj9u8TNqiyhN...|\n",
      "|wNdTKpis6nxehbaZP...|   0|2017-12-17 19:32:32|    0|_yQSKU4yPFz2GxeUg...|  4.0|Really great menu...|     0|KVJEi32OjZUWWPjH1...|\n",
      "|S5FTckOpSK0_Ma4c1...|   1|2013-12-10 05:07:26|    0|330C-YnKno6F57rp5...|  5.0|Found this place ...|     0|WwgRlAGAeIdmG59tV...|\n",
      "+--------------------+----+-------------------+-----+--------------------+-----+--------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "721"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.show(5)\n",
    "reviews_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dummy variable for high reviews (defined as a 4/5 or above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|d_stars|                text|\n",
      "+-------+--------------------+\n",
      "|      1|I don't usually r...|\n",
      "|      0|Food was dece. Se...|\n",
      "|      1|Boca Park Animal ...|\n",
      "|      1|Really great menu...|\n",
      "|      1|Found this place ...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "review_docs_df = reviews_df.withColumn('d_stars',when(col('stars')>=4, 1).otherwise(0))\n",
    "review_docs_df = review_docs_df.select('d_stars', 'text')\n",
    "review_docs_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize 'text' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokenizer object\n",
    "tokenizer = Tokenizer().setInputCol('text').setOutputCol('tokens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now transform the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+\n",
      "|d_stars|                text|              tokens|\n",
      "+-------+--------------------+--------------------+\n",
      "|      1|I don't usually r...|[i, don't, usuall...|\n",
      "|      0|Food was dece. Se...|[food, was, dece....|\n",
      "|      1|Boca Park Animal ...|[boca, park, anim...|\n",
      "|      1|Really great menu...|[really, great, m...|\n",
      "|      1|Found this place ...|[found, this, pla...|\n",
      "|      1|This place is oka...|[this, place, is,...|\n",
      "|      0|I went to Juan's ...|[i, went, to, jua...|\n",
      "|      0|I've eaten at Roc...|[i've, eaten, at,...|\n",
      "|      1|Encore Beach Club...|[encore, beach, c...|\n",
      "|      0|To me, this club ...|[to, me,, this, c...|\n",
      "|      1|Know the owner Co...|[know, the, owner...|\n",
      "|      1|Crazy beers on ta...|[crazy, beers, on...|\n",
      "|      1|Best Hookah spot ...|[best, hookah, sp...|\n",
      "|      0|Good place to sto...|[good, place, to,...|\n",
      "|      0|I came in for din...|[i, came, in, for...|\n",
      "|      1|I have returned t...|[i, have, returne...|\n",
      "|      0|Absolutely, total...|[absolutely,, tot...|\n",
      "|      1|These guys are th...|[these, guys, are...|\n",
      "|      1|Power properties ...|[power, propertie...|\n",
      "|      1|First things firs...|[first, things, f...|\n",
      "+-------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer.transform(review_docs_df).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilize CountVectorizer on new 'tokens' column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `CountVectorizer` is different from a `Tokenizer` because it needs to learn how many different tokens there are in the input column. With that number, it will output vectors with consistent dimensions. Therefore, `CountVectorizer` is an `Estimator` that, when fitted, returns a `Transformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_estimator = CountVectorizer().setInputCol('tokens').setOutputCol('features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to user the words column that was generated by the `tokenizer` transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer_transformer = count_vectorizer_estimator.fit(tokenizer.transform(review_docs_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|d_stars|                text|              tokens|            features|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|      1|I don't usually r...|[i, don't, usuall...|(11816,[0,1,2,3,4...|\n",
      "|      0|Food was dece. Se...|[food, was, dece....|(11816,[6,25,38,4...|\n",
      "|      1|Boca Park Animal ...|[boca, park, anim...|(11816,[0,1,2,4,5...|\n",
      "|      1|Really great menu...|[really, great, m...|(11816,[0,1,4,5,9...|\n",
      "|      1|Found this place ...|[found, this, pla...|(11816,[0,1,2,3,4...|\n",
      "|      1|This place is oka...|[this, place, is,...|(11816,[0,1,2,3,4...|\n",
      "|      0|I went to Juan's ...|[i, went, to, jua...|(11816,[0,1,2,3,4...|\n",
      "|      0|I've eaten at Roc...|[i've, eaten, at,...|(11816,[0,1,2,3,4...|\n",
      "|      1|Encore Beach Club...|[encore, beach, c...|(11816,[0,1,3,4,5...|\n",
      "|      0|To me, this club ...|[to, me,, this, c...|(11816,[0,1,2,3,4...|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer_transformer.transform(tokenizer.transform(review_docs_df)).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Machine Learning Pipeline\n",
    "\n",
    "Sometimes, we have long preprocessing steps that take raw data and transform it through several stages. As explained before, these complex transformations can be captured by Pipelines.\n",
    "\n",
    "Pipelines are always estimators, even when they contain several transformers. After a pipeline is `fit` to the data, the pipeline becomes an transformer.\n",
    "\n",
    "We will now define a pipeline that takes the raw `text` column and produces the `features` column previously explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv_estimator = Pipeline(stages=[tokenizer, count_vectorizer_estimator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_cv_transformer = pipeline_cv_estimator.fit(review_docs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In more complex scenarios, you can even chain Pipeline transformers. We will see this case in the actual use case below.\n",
    "\n",
    "For a more detail explanation of Pipelines, Estimators, and Transformers, [see here](http://spark.apache.org/docs/latest/ml-pipeline.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we obtain the stop words from a website\n",
    "import requests\n",
    "stop_words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words').text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "sw_filter = StopWordsRemover()\\\n",
    "  .setStopWords(stop_words)\\\n",
    "  .setCaseSensitive(False)\\\n",
    "  .setInputCol(\"tokens\")\\\n",
    "  .setOutputCol(\"filtered_tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a counter vectorizer estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# we will remove words that appear in 5 docs or less\n",
    "cv = CountVectorizer(minTF=1., minDF=5., vocabSize=2**17)\\\n",
    "  .setInputCol(\"filtered_tokens\")\\\n",
    "  .setOutputCol(\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now create a pipelined transformer\n",
    "cv_pipeline = Pipeline(stages=[tokenizer, sw_filter, cv]).fit(review_docs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|d_stars|                text|              tokens|     filtered_tokens|                  tf|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      1|I don't usually r...|[i, don't, usuall...|[don't, usually, ...|(1403,[0,6,11,15,...|\n",
      "|      0|Food was dece. Se...|[food, was, dece....|[food, dece., ser...|(1403,[3,4,10,116...|\n",
      "|      1|Boca Park Animal ...|[boca, park, anim...|[boca, park, anim...|(1403,[0,6,9,11,1...|\n",
      "|      1|Really great menu...|[really, great, m...|[really, great, m...|(1403,[2,8,16,55,...|\n",
      "|      1|Found this place ...|[found, this, pla...|[place, yelp., lo...|(1403,[0,1,3,4,5,...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cv_pipeline.transform(review_docs_df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term frequency vector is represented with a sparse vector. We have 26,677 terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1403"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv_pipeline.stages[-1].vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we build another pipeline that takes the output of the previous pipeline and _lowers_ the terms of documents that are very common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF\n",
    "idf = IDF().\\\n",
    "    setInputCol('tf').\\\n",
    "    setOutputCol('tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_pipeline = Pipeline(stages=[cv_pipeline, idf]).fit(review_docs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|d_stars|                text|              tokens|     filtered_tokens|                  tf|               tfidf|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|      1|I don't usually r...|[i, don't, usuall...|[don't, usually, ...|(1403,[0,6,11,15,...|(1403,[0,6,11,15,...|\n",
      "|      0|Food was dece. Se...|[food, was, dece....|[food, dece., ser...|(1403,[3,4,10,116...|(1403,[3,4,10,116...|\n",
      "|      1|Boca Park Animal ...|[boca, park, anim...|[boca, park, anim...|(1403,[0,6,9,11,1...|(1403,[0,6,9,11,1...|\n",
      "|      1|Really great menu...|[really, great, m...|[really, great, m...|(1403,[2,8,16,55,...|(1403,[2,8,16,55,...|\n",
      "|      1|Found this place ...|[found, this, pla...|[place, yelp., lo...|(1403,[0,1,3,4,5,...|(1403,[0,1,3,4,5,...|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf_pipeline.transform(review_docs_df).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, the `idf_pipeline` takes the raw text from the datafarme `imdb_reviews_df` and creates a feature vector called `tfidf`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd_tfidf_df shape = (721, 6)\n"
     ]
    }
   ],
   "source": [
    "tfidf_df = idf_pipeline.transform(review_docs_df)\n",
    "pd_tfidf_df = tfidf_df.toPandas()\n",
    "print(\"pd_tfidf_df shape =\", pd_tfidf_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d_stars</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>(4.277223678772386, 0.0, 0.0, 0.0, 0.0, 0.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>(0.0, 0.0, 0.0, 1.3402781238331838, 1.30902558...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>(4.811876638618934, 0.0, 0.0, 0.0, 0.0, 0.0, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>(0.0, 0.0, 2.422774221530327, 0.0, 0.0, 0.0, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>(0.5346529598465483, 2.331849473376812, 0.0, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d_stars                                              tfidf\n",
       "0        1  (4.277223678772386, 0.0, 0.0, 0.0, 0.0, 0.0, 1...\n",
       "1        0  (0.0, 0.0, 0.0, 1.3402781238331838, 1.30902558...\n",
       "2        1  (4.811876638618934, 0.0, 0.0, 0.0, 0.0, 0.0, 1...\n",
       "3        1  (0.0, 0.0, 2.422774221530327, 0.0, 0.0, 0.0, 0...\n",
       "4        1  (0.5346529598465483, 2.331849473376812, 0.0, 1..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_df = pd_tfidf_df[['d_stars', 'tfidf']]\n",
    "lr_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below prints out the 'tf' and 'tfidf' columns for the first 10 rows of the tfidf_df.  Note that the tfidf column is transformed to account for the frequency with which the word appears in the corpus.  Words that appear more often are penalized more than words that do not appear as frequently in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science pipeline for estimating sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's split the data into training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df, validation_df, testing_df = review_docs_df.randomSplit([0.6, 0.3, 0.1], seed = 151)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|d_stars|                text|\n",
      "+-------+--------------------+\n",
      "|      0|Absolutely, total...|\n",
      "|      0|Good place to sto...|\n",
      "|      0|I came in for din...|\n",
      "|      0|I went to Juan's ...|\n",
      "|      0|To me, this club ...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "training_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[442, 218, 61]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[training_df.count(), validation_df.count(), testing_df.count()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One immediately apparent problem is that the number of features in the dataset is far larger than the number of training examples. This can lead to serious overfitting.\n",
    "\n",
    "Let's look at this more closely. Let's apply a simple prediction model known as logistic regression.\n",
    "\n",
    "[Logistic regression](https://en.wikipedia.org/wiki/Logistic_regression) will take the `tfidf` features and predict whether the review is positive (`score == 1`) or negative (`score == 0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().\\\n",
    "    setLabelCol('score').\\\n",
    "    setFeaturesCol('tfidf').\\\n",
    "    setRegParam(0.0).\\\n",
    "    setMaxIter(100).\\\n",
    "    setElasticNetParam(0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a pipeline transformation by chaining the `idf_pipeline` with the logistic regression step (`lr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipeline = Pipeline(stages=[idf_pipeline, lr]).fit(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets estimate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|      avg(correct)|\n",
      "+------------------+\n",
      "|0.8491076257436452|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_pipeline.transform(validation_df).\\\n",
    "    select(fn.expr('float(prediction = score)').alias('correct')).\\\n",
    "    select(fn.avg('correct')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is much better than before.\n",
    "\n",
    "The problem however is that we are overfitting because we have many features compared to the training examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we look at the weights of the features, there is a lot of noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num weights: 26677\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>br</td>\n",
       "      <td>-0.159518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>-0.011867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>movie</td>\n",
       "      <td>0.107276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>film</td>\n",
       "      <td>0.217781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>t</td>\n",
       "      <td>-0.514780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word    weight\n",
       "0     br -0.159518\n",
       "1      s -0.011867\n",
       "2  movie  0.107276\n",
       "3   film  0.217781\n",
       "4      t -0.514780"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "vocabulary = idf_pipeline.stages[0].stages[-1].vocabulary\n",
    "weights = lr_pipeline.stages[-1].coefficients.toArray()\n",
    "print(\"num weights:\", len(weights))\n",
    "\n",
    "coeffs_df = pd.DataFrame({'word': vocabulary, 'weight': weights})\n",
    "coeffs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most negative words are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>19447</td>\n",
       "      <td>cleaver</td>\n",
       "      <td>-5.989684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19973</td>\n",
       "      <td>unbridled</td>\n",
       "      <td>-4.925661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24671</td>\n",
       "      <td>diligent</td>\n",
       "      <td>-4.616240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26094</td>\n",
       "      <td>disparaging</td>\n",
       "      <td>-4.426469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25566</td>\n",
       "      <td>bigot</td>\n",
       "      <td>-4.271894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              word    weight\n",
       "19447      cleaver -5.989684\n",
       "19973    unbridled -4.925661\n",
       "24671     diligent -4.616240\n",
       "26094  disparaging -4.426469\n",
       "25566        bigot -4.271894"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_df.sort_values('weight').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the most positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20678</td>\n",
       "      <td>praiseworthy</td>\n",
       "      <td>12.804713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25549</td>\n",
       "      <td>storywise</td>\n",
       "      <td>6.461079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24098</td>\n",
       "      <td>flocking</td>\n",
       "      <td>5.092318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25425</td>\n",
       "      <td>appreciable</td>\n",
       "      <td>4.824625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24865</td>\n",
       "      <td>ether</td>\n",
       "      <td>4.714711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word     weight\n",
       "20678  praiseworthy  12.804713\n",
       "25549     storywise   6.461079\n",
       "24098      flocking   5.092318\n",
       "25425   appreciable   4.824625\n",
       "24865         ether   4.714711"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs_df.sort_values('weight', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But none of them make sense. What is happening? We are overfitting the data. Those words that don't make sense are capturing just noise in the reviews.\n",
    "\n",
    "For example, the word `helming` appears in only three reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Rows in helming_pandas_df: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>word</th>\n",
       "      <th>review</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>pos_2548</td>\n",
       "      <td>helming</td>\n",
       "      <td>Karloff and Lugosi - Together again! This is o...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>pos_1550</td>\n",
       "      <td>helming</td>\n",
       "      <td>Fräulein Doktor is as good a demonstration as ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>neg_12396</td>\n",
       "      <td>helming</td>\n",
       "      <td>There aren't many good things to say at all ab...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id     word                                             review  \\\n",
       "0   pos_2548  helming  Karloff and Lugosi - Together again! This is o...   \n",
       "1   pos_1550  helming  Fräulein Doktor is as good a demonstration as ...   \n",
       "2  neg_12396  helming  There aren't many good things to say at all ab...   \n",
       "\n",
       "   score  \n",
       "0    1.0  \n",
       "1    1.0  \n",
       "2    0.0  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helming_df = \\\n",
    "idf_pipeline.transform(training_df).\\\n",
    "    select('id', fn.explode('words').alias('word')).\\\n",
    "    where(fn.col('word') == 'helming').\\\n",
    "    join(training_df, 'id')\n",
    "\n",
    "helming_pandas_df = helming_df.toPandas()\n",
    "\n",
    "print(\"Num Rows in helming_pandas_df:\", len(helming_pandas_df))\n",
    "helming_pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to prevent overfitting during training is to modify the loss function and penalize weight values that are too large.\n",
    "\n",
    "There are two major regularization techniques, one based on penalizing the squared value of the weight (called L2 or ridge regularization) and another based on penalizing the absolute value of the weight (called L1 or lasso regularization).\n",
    "\n",
    "The unregularized logistic regression loss function is:\n",
    "\n",
    "\\begin{equation}\n",
    "L_\\theta(p(X),Y) = - \\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log (1-p_\\theta(X_i)) \\right)\n",
    "\\end{equation}\n",
    "\n",
    "where $p_\\theta(\\cdot)$ is the sigmoid function:\n",
    "\n",
    "\\begin{equation}\n",
    "p_\\theta(X) = \\frac{1}{1+\\exp(-(\\theta_0 + \\sum_{j>0} x_j \\theta_j))}\n",
    "\\end{equation}\n",
    "\n",
    "If we modify the loss function $L_\\theta$ slightly\n",
    "\n",
    "\\begin{equation}\n",
    "L_\\theta^{\\lambda}(p(X),Y) = -\\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log(1-p_\\theta(X_i)) \\right) + \\lambda \\sum_{j>0} \\theta_j^2\n",
    "\\end{equation}\n",
    "\n",
    "we obtain what is known as L2 regularization.\n",
    "\n",
    "Notice how we increase the loss function by $\\lambda$ times the square of the weights. In practice, this means that __we will think twice about increasing the importance of a feature__. This loss function will prevent the algorithm for fitting certain data points, such as outliers or noise, unless the decrease in loss for the data grants it. Also, notice that the penalization doesn't apply to the bias parameter $\\theta_0$.\n",
    "\n",
    "You can see more clearly the effect of such cost function when $\\lambda$ goes to infinity: the features will not be used for predicting and only the bias term will matter! This prevents the algorithm from learning altogether, forcing it to underfit!\n",
    "\n",
    "One problem with L2 regularization is that all weights go to zero uniformly. In a sense, all features will matter but less than with the unregularized loss function. This is a really strange because we do not want all features to matter. In sentiment analysis, we want to select certain features because we want to understand that only some words have effects on the sentiment.\n",
    "\n",
    "A different modification of the original loss function can achieve this. This regularization is known as L1 or lasso reguarlization and penalizes the _absolute_ value of the weight\n",
    "\n",
    "\\begin{equation}\n",
    "L_\\theta^{\\lambda}(p(X),Y) = -\\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log(1-p_\\theta(X_i)) \\right) + \\lambda \\sum_{j>0} \\left| \\theta_j \\right|\n",
    "\\end{equation}\n",
    "\n",
    "The practical effect of L1 regularization is that the difference between a feature having no importance vs some small importance is massively bigger than with L2 regularization. __Therefore, optimizing the L1 loss function usually brings some features to have exactly zero weight.__\n",
    "\n",
    "One problem with L1 regularization is that it will never select more features than the number of examples. This is because it can always fit the training data perfectly when the number of features equals the number of examples. In our sentimental analysis, this is the case (there are more words than examples).\n",
    "\n",
    "One way of remedying this is to have a combination of both L1 and L2. This is known as __elastic net regularization__. For this type of regularization, we have to pick a parameter ($\\alpha$) deciding to consider L1 vs L2 regularization. If $\\alpha=0$, then we choose L2, and if $\\alpha=1$ we choose L1. For example, $\\alpha=0.5$ means half L1 and half L2.\n",
    "\n",
    "\\begin{equation}\n",
    "L_\\theta^{\\lambda,\\alpha}(p(X),Y) = -\\left( \\sum_i Y_i \\log p_\\theta(X_i) + (1-Y_i)\\log (1-p_\\theta(X_i)) \\right) + \\lambda \\left[(1-\\alpha) \\sum_{j>0} \\theta_j^2 + \\alpha \\sum_{j>0} \\left| \\theta_j \\right| \\right]\n",
    "\\end{equation}\n",
    "\n",
    "Unfortunately, elastic net regularization comes with two additional parameters, $\\lambda$ and $\\alpha$, and we must either select them a priori or use the validation set to choose the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark allows us to fit elastic net regularization easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_par = 0.02\n",
    "alpha_par = 0.3\n",
    "en_lr = LogisticRegression().\\\n",
    "        setLabelCol('score').\\\n",
    "        setFeaturesCol('tfidf').\\\n",
    "        setRegParam(lambda_par).\\\n",
    "        setMaxIter(100).\\\n",
    "        setElasticNetParam(alpha_par)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we define a new Pipeline with all steps combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lr_estimator = Pipeline(\n",
    "    stages=[tokenizer, sw_filter, cv, idf, en_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_lr_pipeline = en_lr_estimator.fit(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|avg(float((prediction = score)))|\n",
      "+--------------------------------+\n",
      "|               0.866955110870741|\n",
      "+--------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "en_lr_pipeline.transform(validation_df).select(fn.avg(fn.expr('float(prediction = score)'))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We improve performance slightly, but whats more important is that we improve the understanding of the word sentiments. Lets look at the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_weights = en_lr_pipeline.stages[-1].coefficients.toArray()\n",
    "en_coeffs_df = pd.DataFrame({'word': en_lr_pipeline.stages[2].vocabulary, 'weight': en_weights})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most negative words all make sense (\"worst\" is _actually_ more negative than than \"worse\")!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>worst</td>\n",
       "      <td>-0.359844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>waste</td>\n",
       "      <td>-0.352669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>awful</td>\n",
       "      <td>-0.268944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>bad</td>\n",
       "      <td>-0.252437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>disappointment</td>\n",
       "      <td>-0.222550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>625</td>\n",
       "      <td>poorly</td>\n",
       "      <td>-0.199626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>boring</td>\n",
       "      <td>-0.193945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>249</td>\n",
       "      <td>worse</td>\n",
       "      <td>-0.192057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>547</td>\n",
       "      <td>avoid</td>\n",
       "      <td>-0.181627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>329</td>\n",
       "      <td>horrible</td>\n",
       "      <td>-0.180874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>532</td>\n",
       "      <td>dull</td>\n",
       "      <td>-0.178967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>terrible</td>\n",
       "      <td>-0.177417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1353</td>\n",
       "      <td>redeeming</td>\n",
       "      <td>-0.170272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2885</td>\n",
       "      <td>miscast</td>\n",
       "      <td>-0.160899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>poor</td>\n",
       "      <td>-0.160875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                word    weight\n",
       "104            worst -0.359844\n",
       "253            waste -0.352669\n",
       "204            awful -0.268944\n",
       "11               bad -0.252437\n",
       "1140  disappointment -0.222550\n",
       "625           poorly -0.199626\n",
       "198           boring -0.193945\n",
       "249            worse -0.192057\n",
       "547            avoid -0.181627\n",
       "329         horrible -0.180874\n",
       "532             dull -0.178967\n",
       "221         terrible -0.177417\n",
       "1353       redeeming -0.170272\n",
       "2885         miscast -0.160899\n",
       "178             poor -0.160875"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.sort_values('weight').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing with positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>great</td>\n",
       "      <td>0.292210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>excellent</td>\n",
       "      <td>0.251008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19199</td>\n",
       "      <td>tagged</td>\n",
       "      <td>0.202634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.200991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2205</td>\n",
       "      <td>refreshing</td>\n",
       "      <td>0.180733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>perfect</td>\n",
       "      <td>0.180121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>best</td>\n",
       "      <td>0.178514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>amazing</td>\n",
       "      <td>0.166876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>superb</td>\n",
       "      <td>0.145299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12681</td>\n",
       "      <td>teaming</td>\n",
       "      <td>0.133247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1221</td>\n",
       "      <td>funniest</td>\n",
       "      <td>0.132762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>335</td>\n",
       "      <td>favorite</td>\n",
       "      <td>0.131225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>361</td>\n",
       "      <td>highly</td>\n",
       "      <td>0.130767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>fantastic</td>\n",
       "      <td>0.128540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>991</td>\n",
       "      <td>rare</td>\n",
       "      <td>0.126849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word    weight\n",
       "12          great  0.292210\n",
       "158     excellent  0.251008\n",
       "19199      tagged  0.202634\n",
       "218     wonderful  0.200991\n",
       "2205   refreshing  0.180733\n",
       "223       perfect  0.180121\n",
       "26           best  0.178514\n",
       "319       amazing  0.166876\n",
       "680        superb  0.145299\n",
       "12681     teaming  0.133247\n",
       "1221     funniest  0.132762\n",
       "335      favorite  0.131225\n",
       "361        highly  0.130767\n",
       "588     fantastic  0.128540\n",
       "991          rare  0.126849"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.sort_values('weight', ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there words with _literarily_ zero importance for predicting sentiment? Yes, and most of them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19561, 2)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.query('weight == 0.0').shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In fact, approximately 95% of features are not needed to achieve a __better__ performance than all previous models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9479525078749698"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.query('weight == 0.0').shape[0]/en_coeffs_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at these _neutral_ words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>br</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>movie</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>film</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>like</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>really</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>people</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>don</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>way</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>movies</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>characters</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>character</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>films</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>little</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>know</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  weight\n",
       "0           br     0.0\n",
       "1            s     0.0\n",
       "2        movie     0.0\n",
       "3         film     0.0\n",
       "5         like     0.0\n",
       "10      really     0.0\n",
       "13      people     0.0\n",
       "14         don     0.0\n",
       "15         way     0.0\n",
       "17      movies     0.0\n",
       "20  characters     0.0\n",
       "21   character     0.0\n",
       "22       films     0.0\n",
       "28      little     0.0\n",
       "31        know     0.0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_coeffs_df.query('weight == 0.0').head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, did we choose the right $\\lambda$ and $\\alpha$ parameters? We should run an experiment where we try different combinations of them. Fortunately, Spark let us do this by using a grid - a method that generates combination of parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to build a new estimator pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RegexTokenizer_544481ac1529,\n",
       " StopWordsRemover_26badab38b1a,\n",
       " CountVectorizer_b034ec4fc20d,\n",
       " IDF_484abffecc80,\n",
       " LogisticRegression_c46d76150c3c]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_lr_estimator.getStages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = ParamGridBuilder().\\\n",
    "    addGrid(en_lr.regParam, [0., 0.01, 0.02]).\\\n",
    "    addGrid(en_lr.elasticNetParam, [0., 0.2, 0.4]).\\\n",
    "    build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the list of parameters that we will try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.01,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.0},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2},\n",
       " {Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       "  Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model 1\n",
      "Fitting model 2\n",
      "Fitting model 3\n",
      "Fitting model 4\n",
      "Fitting model 5\n",
      "Fitting model 6\n",
      "Fitting model 7\n",
      "Fitting model 8\n",
      "Fitting model 9\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "for j in range(len(grid)):\n",
    "    print(\"Fitting model {}\".format(j+1))\n",
    "    model = en_lr_estimator.fit(training_df, grid[j])\n",
    "    all_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate the accuracy of each of them:\n",
    "accuracies = [m.\\\n",
    "    transform(validation_df).\\\n",
    "    select(fn.avg(fn.expr('float(score = prediction)')).alias('accuracy')).\\\n",
    "    first().\\\n",
    "    accuracy for m in all_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8497836668469443,\n",
       " 0.8497836668469443,\n",
       " 0.8497836668469443,\n",
       " 0.8688480259599783,\n",
       " 0.872093023255814,\n",
       " 0.8724986479177934,\n",
       " 0.8726338561384532,\n",
       " 0.8747971876690103,\n",
       " 0.8569497025419145]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model index = 7\n"
     ]
    }
   ],
   "source": [
    "best_model_idx = np.argmax(accuracies)\n",
    "print(\"best model index =\", best_model_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the best model we found has the following parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_c46d76150c3c', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       " Param(parent='LogisticRegression_c46d76150c3c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = all_models[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747971876690103"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies[best_model_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          accuracy|\n",
      "+------------------+\n",
      "|0.8852459016393442|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# estimate generalization performance\n",
    "best_model.\\\n",
    "    transform(testing_df).\\\n",
    "    select(fn.avg(fn.expr('float(score = prediction)')).alias('accuracy')).\\\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, predicting tweet sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this model to predict sentiments on Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|                text|         handle|\n",
      "+--------------------+---------------+\n",
      "|RT @ZekeJMiller: ...|@HillaryClinton|\n",
      "|“She’s just out t...|@HillaryClinton|\n",
      "|We're going to ma...|@HillaryClinton|\n",
      "|Don't boo. Vote! ...|@HillaryClinton|\n",
      "|This Republican d...|@HillaryClinton|\n",
      "+--------------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df = spark.read.parquet('tweets.parquet')\n",
    "#tweets_df.show(5, truncate=False)\n",
    "tweets_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1K tweets from each candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------+\n",
      "|          handle|count(1)|\n",
      "+----------------+--------+\n",
      "| @HillaryClinton|    1000|\n",
      "|@realDonaldTrump|    1000|\n",
      "+----------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.groupby('handle').agg(fn.count('*')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now predict the sentiment of the Tweet using our best model, we need to rename the column so that it matches our previous pipeline (`review` => ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+----------+\n",
      "|         handle|              review|prediction|\n",
      "+---------------+--------------------+----------+\n",
      "|@HillaryClinton|RT @ZekeJMiller: ...|       1.0|\n",
      "|@HillaryClinton|“She’s just out t...|       0.0|\n",
      "|@HillaryClinton|We're going to ma...|       0.0|\n",
      "|@HillaryClinton|Don't boo. Vote! ...|       0.0|\n",
      "|@HillaryClinton|This Republican d...|       0.0|\n",
      "|@HillaryClinton|Hillary teamed up...|       0.0|\n",
      "|@HillaryClinton|RT @mayaharris_: ...|       1.0|\n",
      "|@HillaryClinton|\"It was overwhelm...|       0.0|\n",
      "|@HillaryClinton|Great step forwar...|       1.0|\n",
      "|@HillaryClinton|\"I feel like I'm ...|       0.0|\n",
      "|@HillaryClinton|Nobody here was “...|       1.0|\n",
      "|@HillaryClinton|For those few peo...|       1.0|\n",
      "|@HillaryClinton|Remember, don't b...|       1.0|\n",
      "|@HillaryClinton|Too many talented...|       1.0|\n",
      "|@HillaryClinton|There are hundred...|       0.0|\n",
      "|@HillaryClinton|It's 3:20am. As g...|       1.0|\n",
      "|@HillaryClinton|Trump stood on a ...|       1.0|\n",
      "|@HillaryClinton|Donald Trump said...|       1.0|\n",
      "|@HillaryClinton|RT @timkaine: 39 ...|       0.0|\n",
      "|@HillaryClinton|Trump wants to br...|       1.0|\n",
      "+---------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model.transform(tweets_df.withColumnRenamed('text', 'review')).select('handle', 'review', 'prediction').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets summarize our results in a graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pd = best_model.\\\n",
    "    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n",
    "    groupby('handle').\\\n",
    "    agg(fn.avg('prediction').alias('prediction'), (2*fn.stddev('prediction')/fn.sqrt(fn.count('*'))).alias('err')).\\\n",
    "    toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>handle</th>\n",
       "      <th>prediction</th>\n",
       "      <th>err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@HillaryClinton</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.027721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.024519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             handle  prediction       err\n",
       "0   @HillaryClinton       0.741  0.027721\n",
       "1  @realDonaldTrump       0.816  0.024519"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_pd.plot(x='handle', y='prediction', xerr='err', kind='barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But let's examine some \"negative\" tweets by Trump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review='Moderator: Hillary paid $225,000 by a Brazilian bank for a speech that called for “open borders.” That’s a quote! #Debate #BigLeagueTruth'),\n",
       " Row(review='Hillary is too weak to lead on border security-no solutions, no ideas, no credibility.She supported NAFTA, worst deal in US history. #Debate'),\n",
       " Row(review='UNBELIEVABLE!\\nClinton campaign contractor caught in voter-fraud video is a felon who visited White House 342 times: https://t.co/qQdsMHAtkT'),\n",
       " Row(review='More Anti-Catholic Emails From Team Clinton: https://t.co/KYirBbYjp2 https://t.co/f8Z7olUvlM'),\n",
       " Row(review='‘Food Groups’ – Emails Show Clinton Campaign Organized Potential VPs By Race And Gender: https://t.co/Qk1fOm1t8L')]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.\\\n",
    "    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n",
    "    where(fn.col('handle') == '@realDonaldTrump').\\\n",
    "    where(fn.col('prediction') == 0).\\\n",
    "    select('review').\\\n",
    "    take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And Clinton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(review='“She’s just out there every day doing God’s work in her own way. You know? Making her parents proud.” —Betsy, Hilla… https://t.co/ZB3Vxskqoh'),\n",
       " Row(review=\"We're going to make college debt-free for everyone in America. See how much you could save with Hillary's plan at… https://t.co/Fhzkubhpj7\"),\n",
       " Row(review=\"Don't boo. Vote! https://t.co/tTgeqy51PU https://t.co/9un3FUVxoG\"),\n",
       " Row(review='This Republican dad is struggling with the idea of his daughter growing up in a country led by Donald Trump. https://t.co/Tn3rQqJJKp'),\n",
       " Row(review='Hillary teamed up with @BernieSanders on a plan to make college debt-free for all Americans. https://t.co/sdWVzdxIrG')]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.\\\n",
    "    transform(tweets_df.withColumnRenamed('text', 'review')).\\\n",
    "    where(fn.col('handle') == '@HillaryClinton').\\\n",
    "    where(fn.col('prediction') == 0).\\\n",
    "    select('review').\\\n",
    "    take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are lots of room for improvement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
